{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a80d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T11:54:51.556172300Z",
     "start_time": "2023-06-01T11:54:50.556467700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='hfl/rbt3', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/加载tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('hfl/rbt3')\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abc8bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3209, 3299, 6163, 7652, 749, 872, 4638, 4970, 2094, 102], [101, 872, 6163, 7652, 749, 1166, 782, 4638, 3457, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/试编码句子\n",
    "tokenizer.batch_encode_plus(\n",
    "    ['明月装饰了你的窗子', '你装饰了别人的梦'],\n",
    "    truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66296e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/从磁盘加载数据集\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk('../data/ChnSentiCorp')\n",
    "\n",
    "#缩小数据规模，便于测试\n",
    "dataset['train'] = dataset['train'].shuffle().select(range(2000))\n",
    "dataset['test'] = dataset['test'].shuffle().select(range(100))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fe256d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at D:\\workspace\\learning-huggingface\\data\\ChnSentiCorp\\validation\\cache-4da7acca9537a086.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/编码\n",
    "# from transformers import AutoTokenizer\n",
    "#\n",
    "# tokenizer = AutoTokenizer.from_pretrained('hfl/rbt3')\n",
    "def f(data):\n",
    "    return tokenizer.batch_encode_plus(data['text'], truncation=True)\n",
    "\n",
    "\n",
    "dataset = dataset.map(f,\n",
    "                      batched=True,\n",
    "                      batch_size=1000,\n",
    "                      num_proc=1,\n",
    "                      remove_columns=['text'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcbaae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at D:\\workspace\\learning-huggingface\\data\\ChnSentiCorp\\validation\\cache-3eeeed8a3981ac50_*_of_00004.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=4):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1975\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 98\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/移除太长的句子\n",
    "def f(data):\n",
    "    return [len(i) <= 512 for i in data['input_ids']]\n",
    "\n",
    "\n",
    "dataset = dataset.filter(f, batched=True, batch_size=1000, num_proc=4)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57bf2514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/rbt3 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3847.8338"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/加载模型\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('hfl/rbt3',\n",
    "                                                           num_labels=2)\n",
    "\n",
    "#统计模型参数量\n",
    "sum([i.nelement() for i in model.parameters()]) / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f04e678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4832, grad_fn=<NllLossBackward0>), torch.Size([4, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/模型试算\n",
    "import torch\n",
    "\n",
    "#模拟一批数据\n",
    "data = {\n",
    "    'input_ids': torch.ones(4, 10, dtype=torch.long),\n",
    "    'token_type_ids': torch.ones(4, 10, dtype=torch.long),\n",
    "    'attention_mask': torch.ones(4, 10, dtype=torch.long),\n",
    "    'labels': torch.ones(4, dtype=torch.long)\n",
    "}\n",
    "\n",
    "#模型试算\n",
    "out = model(**data)\n",
    "\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af634042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #第6章/加载评价指标\n",
    "# from datasets import load_metric\n",
    "# metric = load_metric('accuracy')\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f21c40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/定义评价函数\n",
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = logits.argmax(axis=1)\n",
    "    return {'accuracy': (logits == labels).sum() / len(labels)}\n",
    "    #return metric.compute(predictions=logits, references=labels)\n",
    "\n",
    "\n",
    "#模拟输出\n",
    "eval_pred = EvalPrediction(\n",
    "    predictions=np.array([[0, 1], [2, 3], [4, 5], [6, 7]]),\n",
    "    label_ids=np.array([1, 1, 0, 1]),\n",
    ")\n",
    "\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0126225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/定义训练参数\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "#定义训练参数\n",
    "args = TrainingArguments(\n",
    "    #定义临时数据保存路径\n",
    "    output_dir='./output_dir',\n",
    "\n",
    "    #定义测试执行的策略，可取值no、epoch、steps\n",
    "    evaluation_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step执行一次测试\n",
    "    eval_steps=30,\n",
    "\n",
    "    #定义模型保存策略，可取值no、epoch、steps\n",
    "    save_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step保存一次\n",
    "    save_steps=30,\n",
    "\n",
    "    #定义共训练几个轮次\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    #定义学习率\n",
    "    learning_rate=1e-4,\n",
    "\n",
    "    #加入参数权重衰减，防止过拟合\n",
    "    weight_decay=1e-2,\n",
    "\n",
    "    #定义测试和训练时的批次大小\n",
    "    per_device_eval_batch_size=16,\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    #定义是否要使用gpu训练\n",
    "    no_cuda=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87784ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/定义训练器\n",
    "from transformers import Trainer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "#定义训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6968ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "49\n",
      "85\n",
      "76\n",
      "65\n",
      "input_ids torch.Size([5, 85])\n",
      "token_type_ids torch.Size([5, 85])\n",
      "attention_mask torch.Size([5, 85])\n",
      "labels torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "#第6章/测试数据整理函数\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "#获取一批数据\n",
    "data = dataset['train'][:5]\n",
    "\n",
    "#输出这些句子的长度\n",
    "for i in data['input_ids']:\n",
    "    print(len(i))\n",
    "\n",
    "#调用数据整理函数\n",
    "data = data_collator(data)\n",
    "\n",
    "#查看整理后的数据\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b433850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 正 在 刷 新 bios 、 装 xp 系 统 、 装 驱 动 ， 工 程 没 完 ， 不 知 道 长 期 使 用 怎 么 样 。 听 网 上 说 无 线 网 卡 有 些 问 题 ， 有 点 怕 ！ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f8ae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 02:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\thinkpad/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\workspace\\learning-huggingface\\chapter-6\\wandb\\run-20230601_195836-pelbdqxm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/atjapan2015/huggingface/runs/pelbdqxm' target=\"_blank\">proud-frost-1</a></strong> to <a href='https://wandb.ai/atjapan2015/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/atjapan2015/huggingface' target=\"_blank\">https://wandb.ai/atjapan2015/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/atjapan2015/huggingface/runs/pelbdqxm' target=\"_blank\">https://wandb.ai/atjapan2015/huggingface/runs/pelbdqxm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7289360761642456,\n",
       " 'eval_accuracy': 0.5204081632653061,\n",
       " 'eval_runtime': 1.9807,\n",
       " 'eval_samples_per_second': 49.476,\n",
       " 'eval_steps_per_second': 3.534}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe282744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.351372</td>\n",
       "      <td>0.836735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283773</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328433</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380387</td>\n",
       "      <td>0.836735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=0.3940151891400737, metrics={'train_runtime': 6.0259, 'train_samples_per_second': 327.754, 'train_steps_per_second': 20.578, 'total_flos': 69927521442396.0, 'train_loss': 0.3940151891400737, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee639afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.348675</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=0.0632401704788208, metrics={'train_runtime': 1.4428, 'train_samples_per_second': 1368.867, 'train_steps_per_second': 85.944, 'total_flos': 67822927473180.0, 'train_loss': 0.0632401704788208, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/从某个存档继续训练\n",
    "trainer.train(resume_from_checkpoint='./output_dir/checkpoint-90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7a0bf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34703460335731506,\n",
       " 'eval_accuracy': 0.8979591836734694,\n",
       " 'eval_runtime': 0.0803,\n",
       " 'eval_samples_per_second': 1219.995,\n",
       " 'eval_steps_per_second': 87.142,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00182f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/手动保存模型参数\n",
    "trainer.save_model(output_dir='./output_dir/save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6bd26d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/手动加载模型参数\n",
    "import torch\n",
    "\n",
    "model.load_state_dict(torch.load('./output_dir/save_model/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff923914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "携 程 定 的 不 带 早 饭 ， 所 以 不 能 评 价 吃 的 。 总 体 来 说 装 修 不 错 ， 没 有 什 么 特 别 大 的 毛 病 。 停 车 先 收 20 快 一 天 ， 最 后 到 前 台 报 销 。 空 调 非 常 足 ， 都 有 点 过 热 了 。 这 个 价 位 住 到 这 样 子 的 酒 店 ， 非 常 好 了 。 感 觉 比 较 适 合 家 庭 出 游 。 上 网 贵 的 就 是 不 要 上 网 了 ， 比 较 黑 。\n",
      "label= 1\n",
      "predict= 1\n",
      "猫 和 老 鼠 的 dvd, 我 在 当 当 网 已 买 过 10 余 次 了 。 除 了 做 为 礼 物 送 给 亲 朋 好 有 的 孩 子 外 ， 还 留 下 自 己 观 看 ， 而 且 是 百 看 不 厌......\n",
      "label= 0\n",
      "predict= 0\n",
      "充 其 量 一 个 度 假 村 而 已 ， 客 房 其 实 并 不 大 ， 不 知 通 过 什 么 手 段 评 上 4 星 了 。 酒 店 近 邻 104 国 道 ， 是 连 套 别 墅 销 售 附 带 的 设 施 。 房 间 装 修 味 道 很 大 ， 其 中 一 个 房 子 竟 然 没 有 窗 户 。 卫 生 间 一 股 臭 味 ， 设 施 还 不 如 3 星 级 酒 店 。 如 果 不 是 去 山 东 路 上 太 晚 ， 怎 么 也 不 会 到 这 个 酒 店 。\n",
      "label= 0\n",
      "predict= 0\n",
      "书 本 的 质 量 很 差 ： 收 到 的 书 本 前 面 几 页 装 订 反 了 ， 有 几 页 本 来 就 没 有 装 订 好 ， 直 接 就 可 以 拿 下 来 。 寄 回 当 当 网 换 货 ， 20 多 天 了 ， 一 点 消 息 都 没 有 ， 写 了 邮 件 通 知 换 货 的 原 因 ， 却 没 有 见 到 任 何 回 复 。 为 了 要 换 货 ， 我 还 要 特 意 去 跑 一 趟 邮 局 。 这 次 买 书 简 直 是 受 气 。 这 样 的 服 务 也 太 差 了 。\n",
      "label= 0\n",
      "predict= 0\n",
      "酒 店 比 较 旧 ， 不 符 合 四 星 标 准 ， 出 行 不 是 很 方 便 。\n",
      "label= 0\n",
      "predict= 0\n",
      "没 有 许 多 网 友 评 价 热 度 高 的 问 题 ， 第 一 次 要 手 动 安 装 winxp ， 主 板 的 blis - 硬 盘 重 新 设 置\n",
      "label= 1\n",
      "predict= 0\n",
      "2007 年 9 月 11 日 256 元 住 普 通 标 间 ， 临 街 （ 其 它 房 型 已 无 ） 。 我 是 喜 欢 开 着 窗 睡 觉 的 ， 总 体 感 觉 不 太 吵 。 因 为 下 面 的 玉 皇 阁 北 街 不 算 是 银 川 的 主 要 交 通 要 道 。 早 上 有 一 些 车 流 声 。 对 面 有 个 农 贸 市 场 ， 购 买 应 季 瓜 果 很 方 便 。 离 鼓 楼 不 远 ， 可 以 品 尝 一 下 老 毛 抓 肉 。\n",
      "label= 1\n",
      "predict= 0\n",
      "挺 悲 哀 的, 住 的 是 双 标 间 国 庆 是 230, 在 杭 州 住 了 个 锦 华 之 旅 已 经 很 挫 了, 这 位 仁 兄 有 过 之 而 无 不 及, 依 然 的 一 阵 阵 怪 味, 纱 窗 坏 的, 空 调 乱 叫, 唯 一 的 好 处 就 是 代 售 附 近 的 景 点 ( 如 : 浙 西 大 峡 谷, 天 滩, 大 明 山 等 ) 门 票 八 五 折, 本 身 在 携 程 订 的 是 两 晚, 连 忙 把 第 二 晚 的 给 退 了, 听 当 天 把 我 们 带 到 天 滩 的 司 机 介 绍 住 在 大 峡 谷 镇 的 一 个 旅 店.\n",
      "label= 0\n",
      "predict= 0\n",
      "第 一 次 买 的 拉 拉 升 职 记 ， 三 天 到 货 （ 我 住 北 京 三 环 边 上 ） ， 还 比 较 满 意 ． 第 二 又 买 ＜ 明 朝 那 些 事 ＞ ， ６ 月 ２２ 订 的 书 ， 一 个 星 期 没 收 到 ， 打 客 服 ， 回 答 一 律 是 很 抱 歉 ， 两 个 星 期 还 没 收 到 ， 就 在 我 要 奋 起 反 抗 的 时 候 ， 收 到 当 当 网 的 短 信 ， 说 是 订 单 找 不 到 了 ， 让 我 重 新 订 货 ． 天 底 下 还 有 这 么 无 耻 的 服 务 吗 ？ 我 重 新 订 货 时 发 现 ， 书 的 折 扣 少 了 １０ ％ ， 也 就 是 说 涨 价 了 ． 重 新 打 客 服 ， 客 服 看 到 我 的 订 货 日 期 乃 是 遥 远 的 半 个 多 月 前 ， 就 答 应 给 我 申 请 礼 券 后 再 重 新 订 货 ， 并 保 证 说 下 午 礼 券 就 到 账 户 ． 我 等 啊 等 ， 又 等 了 一 天 半 ， 还 是 没 有 任 何 礼 券 ． 却 在 今 天 ， 也 就 是 ７ 月 １０ 日 ， 我 订 的 书 终 于 以 超 越 思 维 的 速 度 来 到 我 的 面 前 ． 敢 问 当 当 ， 这 是 你 们 的 一 贯 作 风 吗 ？ 对 由 此 让 我 产 生 的 那 些 愤 怒 的 不 良 情 绪 而 导 致 的 身 体 不 适 的 损 失 你 们 打 算 如 何 赔 偿 呢 ？\n",
      "label= 0\n",
      "predict= 0\n",
      "刚 刚 入 住 是 发 现 房 间 的 地 毯 和 椅 子 都 是 湿 的 ， 打 电 话 询 问 时 前 台 只 是 说 明 了 为 什 么 椅 子 和 地 毯 会 是 湿 的 、 一 点 歉 意 都 没 感 觉 到 。 结 果 只 给 换 了 两 把 椅 子 ， 实 在 有 些 让 人 不 爽 。 离 五 星 级 服 务 还 有 距 离 。\n",
      "label= 0\n",
      "predict= 0\n",
      "问 题 多. 刚 买 回 来 光 驱 弹 不 出 来, 必 须 用 针 弄 出 来 ！ 无 奈 之 下 第 二 天 就 去 了 维 修 站 拆 机 修 了 ， 但 有 事 还 是 不 灵 ， 后 来 又 发 现 待 机 无 法 唤 醒 ！ 打 了 客 服 电 话 说 要 我 刷 主 板 ！ 如 拿 他 那 修 机 器 还 拿 不 回 来 ！ 明 显 主 板 有 问 题\n",
      "label= 1\n",
      "predict= 0\n",
      "非 常 好 用 ， 速 度 也 不 错 ， 特 别 好 用 ， 做 工 非 常 棒 ， 经 典 好 东 西 ， 早 买 早 享 受\n",
      "label= 1\n",
      "predict= 1\n",
      "1. 散 热 性 能 较 好 2. 多 媒 体 触 摸 按 钮 很 有 新 意 ， 也 方 便 操 作 3. 触 摸 板 灵 敏 ， 好 用 4. 512m 显 存 对 外 接 大 显 示 器 / 高 清 电 视 有 很 大 的 帮 助 5. 预 装 linux 系 统 ， 实 惠 6. 京 东 速 度 快 ， 值 得 信 赖\n",
      "label= 1\n",
      "predict= 1\n",
      "内 容 太 棒 了 ， 插 图 轻 松 幽 默 ， 语 言 通 俗 易 懂 ， 看 得 不 累 ， 而 且 对 猫 猫 的 心 理 描 写 让 我 对 猫 猫 懂 得 了 更 多 ， 那 天 在 小 区 楼 下 的 花 园 里 观 察 经 常 出 没 的 流 浪 猫 ， 一 只 公 猫 嗅 着 另 一 只 母 猫 的 尿 液 后 因 为 嗅 觉 的 满 足 ， 流 露 出 的 表 情 果 然 会 咧 嘴 笑 ， 很 神 奇 呢 ， 当 我 对 身 边 的 人 说 出 我 的 观 察 结 果 ， 很 多 人 都 表 示 惊 讶 神 奇 ， 虽 然 很 多 人 都 有 养 猫 ， 但 猫 的 心 理 很 多 人 都 不 曾 认 真 深 入 了 解 。 这 本 书 实 在 写 得 太 精 彩 了 。\n",
      "label= 1\n",
      "predict= 1\n",
      "太 好 看 了 真 是 一 本 好 书 一 本 让 人 爱 不 释 手 的 好 书 这 还 是 第 一 本 被 我 放 在 我 家 典 藏 书 架 的 第 一 本 动 物 小 说 ！ 希 望 能 在 出 一 本 好 好 书 顶 ~ 顶 牧 玲 爷 爷 ！\n",
      "label= 1\n",
      "predict= 0\n",
      "第 一 次 入 住 这 家 酒 店 ， 总 体 感 觉 不 错 ， 服 务 员 笑 脸 相 迎 ， 服 务 周 到 ， 房 间 干 净 、 温 馨 ， 豪 华 房 还 配 有 液 晶 电 脑 可 以 免 费 上 网 ， 而 且 网 速 很 快 ， 值 得 推 荐 。 下 次 到 深 圳 ， 还 住 这 家 酒 店 。 宾 馆 反 馈 2008 年 8 月 5 日 ： 尊 敬 的 宾 客 您 好 ！ 首 先 ， 非 常 感 谢 您 给 予 我 店 的 好 评 。 同 时 ， 很 高 兴 地 告 知 您 ， 我 店 的 网 络 光 纤 已 从 原 来 的 2 兆 升 级 到 了 5 兆 ， 极 大 地 提 升 了 网 络 速 度 ， 无 论 是 商 务 办 公 还 是 网 上 冲 浪 都 更 加 方 便 快 捷 。 不 断 地 提 高 服 务 水 平 ， 为 宾 客 提 供 更 优 质 服 务 是 我 们 的 宗 旨 ！ 我 们 真 诚 地 欢 迎 您 再 次 光 临 ！\n",
      "label= 1\n",
      "predict= 1\n"
     ]
    }
   ],
   "source": [
    "#第6章/测试\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(trainer.get_eval_dataloader()):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    data[k] = v.to('cuda')\n",
    "\n",
    "out = model(**data)\n",
    "out = out['logits'].argmax(dim=1)\n",
    "\n",
    "for i in range(16):\n",
    "    print(tokenizer.decode(data['input_ids'][i], skip_special_tokens=True))\n",
    "    print('label=', data['labels'][i].item())\n",
    "    print('predict=', out[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "403170ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.75}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/定义评价函数\n",
    "import numpy as np\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = logits.argmax(axis=1)\n",
    "    return {'accuracy': (logits == labels).sum() / len(labels)}\n",
    "    #return metric.compute(predictions=logits, references=labels)\n",
    "\n",
    "\n",
    "#模拟输出\n",
    "eval_pred = EvalPrediction(\n",
    "    predictions=np.array([[0, 1], [2, 3], [4, 5], [6, 7]]),\n",
    "    label_ids=np.array([1, 1, 0, 1]),\n",
    ")\n",
    "\n",
    "compute_metrics(eval_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d86c46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/定义训练参数\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "#定义训练参数\n",
    "args = TrainingArguments(\n",
    "    #定义临时数据保存路径\n",
    "    output_dir='./output_dir',\n",
    "\n",
    "    #定义测试执行的策略，可取值no、epoch、steps\n",
    "    evaluation_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step执行一次测试\n",
    "    eval_steps=30,\n",
    "\n",
    "    #定义模型保存策略，可取值no、epoch、steps\n",
    "    save_strategy='steps',\n",
    "\n",
    "    #定义每隔多少个step保存一次\n",
    "    save_steps=30,\n",
    "\n",
    "    #定义共训练几个轮次\n",
    "    num_train_epochs=1,\n",
    "\n",
    "    #定义学习率\n",
    "    learning_rate=1e-4,\n",
    "\n",
    "    #加入参数权重衰减，防止过拟合\n",
    "    weight_decay=1e-2,\n",
    "\n",
    "    #定义测试和训练时的批次大小\n",
    "    per_device_eval_batch_size=16,\n",
    "    per_device_train_batch_size=16,\n",
    "\n",
    "    #定义是否要使用gpu训练\n",
    "    no_cuda=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5748cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/定义训练器\n",
    "from transformers import Trainer\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "#定义训练器\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ab1ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "49\n",
      "85\n",
      "76\n",
      "65\n",
      "input_ids torch.Size([5, 85])\n",
      "token_type_ids torch.Size([5, 85])\n",
      "attention_mask torch.Size([5, 85])\n",
      "labels torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "#第6章/测试数据整理函数\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "#获取一批数据\n",
    "data = dataset['train'][:5]\n",
    "\n",
    "#输出这些句子的长度\n",
    "for i in data['input_ids']:\n",
    "    print(len(i))\n",
    "\n",
    "#调用数据整理函数\n",
    "data = data_collator(data)\n",
    "\n",
    "#查看整理后的数据\n",
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ac07ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 正 在 刷 新 bios 、 装 xp 系 统 、 装 驱 动 ， 工 程 没 完 ， 不 知 道 长 期 使 用 怎 么 样 。 听 网 上 说 无 线 网 卡 有 些 问 题 ， 有 点 怕 ！ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7508e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34703460335731506,\n",
       " 'eval_accuracy': 0.8979591836734694,\n",
       " 'eval_runtime': 0.0792,\n",
       " 'eval_samples_per_second': 1237.951,\n",
       " 'eval_steps_per_second': 88.425}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2861051f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.492852</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.400477</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316759</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.395314</td>\n",
       "      <td>0.846939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=0.24466546889274352, metrics={'train_runtime': 5.4675, 'train_samples_per_second': 361.227, 'train_steps_per_second': 22.68, 'total_flos': 69927521442396.0, 'train_loss': 0.24466546889274352, 'epoch': 1.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5971dd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='124' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [124/124 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244510</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=124, training_loss=0.04930720790739982, metrics={'train_runtime': 1.4296, 'train_samples_per_second': 1381.513, 'train_steps_per_second': 86.738, 'total_flos': 67822927473180.0, 'train_loss': 0.04930720790739982, 'epoch': 1.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/从某个存档继续训练\n",
    "trainer.train(resume_from_checkpoint='./output_dir/checkpoint-90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22dc37ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.24330143630504608,\n",
       " 'eval_accuracy': 0.9285714285714286,\n",
       " 'eval_runtime': 0.0824,\n",
       " 'eval_samples_per_second': 1189.336,\n",
       " 'eval_steps_per_second': 84.953,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/评价模型\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d024896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#第6章/手动保存模型参数\n",
    "trainer.save_model(output_dir='./output_dir/save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c386463d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#第6章/手动加载模型参数\n",
    "import torch\n",
    "\n",
    "model.load_state_dict(torch.load('./output_dir/save_model/pytorch_model.bin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c46f3818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "携 程 定 的 不 带 早 饭 ， 所 以 不 能 评 价 吃 的 。 总 体 来 说 装 修 不 错 ， 没 有 什 么 特 别 大 的 毛 病 。 停 车 先 收 20 快 一 天 ， 最 后 到 前 台 报 销 。 空 调 非 常 足 ， 都 有 点 过 热 了 。 这 个 价 位 住 到 这 样 子 的 酒 店 ， 非 常 好 了 。 感 觉 比 较 适 合 家 庭 出 游 。 上 网 贵 的 就 是 不 要 上 网 了 ， 比 较 黑 。\n",
      "label= 1\n",
      "predict= 1\n",
      "猫 和 老 鼠 的 dvd, 我 在 当 当 网 已 买 过 10 余 次 了 。 除 了 做 为 礼 物 送 给 亲 朋 好 有 的 孩 子 外 ， 还 留 下 自 己 观 看 ， 而 且 是 百 看 不 厌......\n",
      "label= 0\n",
      "predict= 1\n",
      "充 其 量 一 个 度 假 村 而 已 ， 客 房 其 实 并 不 大 ， 不 知 通 过 什 么 手 段 评 上 4 星 了 。 酒 店 近 邻 104 国 道 ， 是 连 套 别 墅 销 售 附 带 的 设 施 。 房 间 装 修 味 道 很 大 ， 其 中 一 个 房 子 竟 然 没 有 窗 户 。 卫 生 间 一 股 臭 味 ， 设 施 还 不 如 3 星 级 酒 店 。 如 果 不 是 去 山 东 路 上 太 晚 ， 怎 么 也 不 会 到 这 个 酒 店 。\n",
      "label= 0\n",
      "predict= 0\n",
      "书 本 的 质 量 很 差 ： 收 到 的 书 本 前 面 几 页 装 订 反 了 ， 有 几 页 本 来 就 没 有 装 订 好 ， 直 接 就 可 以 拿 下 来 。 寄 回 当 当 网 换 货 ， 20 多 天 了 ， 一 点 消 息 都 没 有 ， 写 了 邮 件 通 知 换 货 的 原 因 ， 却 没 有 见 到 任 何 回 复 。 为 了 要 换 货 ， 我 还 要 特 意 去 跑 一 趟 邮 局 。 这 次 买 书 简 直 是 受 气 。 这 样 的 服 务 也 太 差 了 。\n",
      "label= 0\n",
      "predict= 0\n",
      "酒 店 比 较 旧 ， 不 符 合 四 星 标 准 ， 出 行 不 是 很 方 便 。\n",
      "label= 0\n",
      "predict= 0\n",
      "没 有 许 多 网 友 评 价 热 度 高 的 问 题 ， 第 一 次 要 手 动 安 装 winxp ， 主 板 的 blis - 硬 盘 重 新 设 置\n",
      "label= 1\n",
      "predict= 0\n",
      "2007 年 9 月 11 日 256 元 住 普 通 标 间 ， 临 街 （ 其 它 房 型 已 无 ） 。 我 是 喜 欢 开 着 窗 睡 觉 的 ， 总 体 感 觉 不 太 吵 。 因 为 下 面 的 玉 皇 阁 北 街 不 算 是 银 川 的 主 要 交 通 要 道 。 早 上 有 一 些 车 流 声 。 对 面 有 个 农 贸 市 场 ， 购 买 应 季 瓜 果 很 方 便 。 离 鼓 楼 不 远 ， 可 以 品 尝 一 下 老 毛 抓 肉 。\n",
      "label= 1\n",
      "predict= 1\n",
      "挺 悲 哀 的, 住 的 是 双 标 间 国 庆 是 230, 在 杭 州 住 了 个 锦 华 之 旅 已 经 很 挫 了, 这 位 仁 兄 有 过 之 而 无 不 及, 依 然 的 一 阵 阵 怪 味, 纱 窗 坏 的, 空 调 乱 叫, 唯 一 的 好 处 就 是 代 售 附 近 的 景 点 ( 如 : 浙 西 大 峡 谷, 天 滩, 大 明 山 等 ) 门 票 八 五 折, 本 身 在 携 程 订 的 是 两 晚, 连 忙 把 第 二 晚 的 给 退 了, 听 当 天 把 我 们 带 到 天 滩 的 司 机 介 绍 住 在 大 峡 谷 镇 的 一 个 旅 店.\n",
      "label= 0\n",
      "predict= 0\n",
      "第 一 次 买 的 拉 拉 升 职 记 ， 三 天 到 货 （ 我 住 北 京 三 环 边 上 ） ， 还 比 较 满 意 ． 第 二 又 买 ＜ 明 朝 那 些 事 ＞ ， ６ 月 ２２ 订 的 书 ， 一 个 星 期 没 收 到 ， 打 客 服 ， 回 答 一 律 是 很 抱 歉 ， 两 个 星 期 还 没 收 到 ， 就 在 我 要 奋 起 反 抗 的 时 候 ， 收 到 当 当 网 的 短 信 ， 说 是 订 单 找 不 到 了 ， 让 我 重 新 订 货 ． 天 底 下 还 有 这 么 无 耻 的 服 务 吗 ？ 我 重 新 订 货 时 发 现 ， 书 的 折 扣 少 了 １０ ％ ， 也 就 是 说 涨 价 了 ． 重 新 打 客 服 ， 客 服 看 到 我 的 订 货 日 期 乃 是 遥 远 的 半 个 多 月 前 ， 就 答 应 给 我 申 请 礼 券 后 再 重 新 订 货 ， 并 保 证 说 下 午 礼 券 就 到 账 户 ． 我 等 啊 等 ， 又 等 了 一 天 半 ， 还 是 没 有 任 何 礼 券 ． 却 在 今 天 ， 也 就 是 ７ 月 １０ 日 ， 我 订 的 书 终 于 以 超 越 思 维 的 速 度 来 到 我 的 面 前 ． 敢 问 当 当 ， 这 是 你 们 的 一 贯 作 风 吗 ？ 对 由 此 让 我 产 生 的 那 些 愤 怒 的 不 良 情 绪 而 导 致 的 身 体 不 适 的 损 失 你 们 打 算 如 何 赔 偿 呢 ？\n",
      "label= 0\n",
      "predict= 0\n",
      "刚 刚 入 住 是 发 现 房 间 的 地 毯 和 椅 子 都 是 湿 的 ， 打 电 话 询 问 时 前 台 只 是 说 明 了 为 什 么 椅 子 和 地 毯 会 是 湿 的 、 一 点 歉 意 都 没 感 觉 到 。 结 果 只 给 换 了 两 把 椅 子 ， 实 在 有 些 让 人 不 爽 。 离 五 星 级 服 务 还 有 距 离 。\n",
      "label= 0\n",
      "predict= 0\n",
      "问 题 多. 刚 买 回 来 光 驱 弹 不 出 来, 必 须 用 针 弄 出 来 ！ 无 奈 之 下 第 二 天 就 去 了 维 修 站 拆 机 修 了 ， 但 有 事 还 是 不 灵 ， 后 来 又 发 现 待 机 无 法 唤 醒 ！ 打 了 客 服 电 话 说 要 我 刷 主 板 ！ 如 拿 他 那 修 机 器 还 拿 不 回 来 ！ 明 显 主 板 有 问 题\n",
      "label= 1\n",
      "predict= 0\n",
      "非 常 好 用 ， 速 度 也 不 错 ， 特 别 好 用 ， 做 工 非 常 棒 ， 经 典 好 东 西 ， 早 买 早 享 受\n",
      "label= 1\n",
      "predict= 1\n",
      "1. 散 热 性 能 较 好 2. 多 媒 体 触 摸 按 钮 很 有 新 意 ， 也 方 便 操 作 3. 触 摸 板 灵 敏 ， 好 用 4. 512m 显 存 对 外 接 大 显 示 器 / 高 清 电 视 有 很 大 的 帮 助 5. 预 装 linux 系 统 ， 实 惠 6. 京 东 速 度 快 ， 值 得 信 赖\n",
      "label= 1\n",
      "predict= 1\n",
      "内 容 太 棒 了 ， 插 图 轻 松 幽 默 ， 语 言 通 俗 易 懂 ， 看 得 不 累 ， 而 且 对 猫 猫 的 心 理 描 写 让 我 对 猫 猫 懂 得 了 更 多 ， 那 天 在 小 区 楼 下 的 花 园 里 观 察 经 常 出 没 的 流 浪 猫 ， 一 只 公 猫 嗅 着 另 一 只 母 猫 的 尿 液 后 因 为 嗅 觉 的 满 足 ， 流 露 出 的 表 情 果 然 会 咧 嘴 笑 ， 很 神 奇 呢 ， 当 我 对 身 边 的 人 说 出 我 的 观 察 结 果 ， 很 多 人 都 表 示 惊 讶 神 奇 ， 虽 然 很 多 人 都 有 养 猫 ， 但 猫 的 心 理 很 多 人 都 不 曾 认 真 深 入 了 解 。 这 本 书 实 在 写 得 太 精 彩 了 。\n",
      "label= 1\n",
      "predict= 1\n",
      "太 好 看 了 真 是 一 本 好 书 一 本 让 人 爱 不 释 手 的 好 书 这 还 是 第 一 本 被 我 放 在 我 家 典 藏 书 架 的 第 一 本 动 物 小 说 ！ 希 望 能 在 出 一 本 好 好 书 顶 ~ 顶 牧 玲 爷 爷 ！\n",
      "label= 1\n",
      "predict= 0\n",
      "第 一 次 入 住 这 家 酒 店 ， 总 体 感 觉 不 错 ， 服 务 员 笑 脸 相 迎 ， 服 务 周 到 ， 房 间 干 净 、 温 馨 ， 豪 华 房 还 配 有 液 晶 电 脑 可 以 免 费 上 网 ， 而 且 网 速 很 快 ， 值 得 推 荐 。 下 次 到 深 圳 ， 还 住 这 家 酒 店 。 宾 馆 反 馈 2008 年 8 月 5 日 ： 尊 敬 的 宾 客 您 好 ！ 首 先 ， 非 常 感 谢 您 给 予 我 店 的 好 评 。 同 时 ， 很 高 兴 地 告 知 您 ， 我 店 的 网 络 光 纤 已 从 原 来 的 2 兆 升 级 到 了 5 兆 ， 极 大 地 提 升 了 网 络 速 度 ， 无 论 是 商 务 办 公 还 是 网 上 冲 浪 都 更 加 方 便 快 捷 。 不 断 地 提 高 服 务 水 平 ， 为 宾 客 提 供 更 优 质 服 务 是 我 们 的 宗 旨 ！ 我 们 真 诚 地 欢 迎 您 再 次 光 临 ！\n",
      "label= 1\n",
      "predict= 1\n"
     ]
    }
   ],
   "source": [
    "#第6章/测试\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(trainer.get_eval_dataloader()):\n",
    "    break\n",
    "\n",
    "for k, v in data.items():\n",
    "    data[k] = v.to('cuda')\n",
    "\n",
    "out = model(**data)\n",
    "out = out['logits'].argmax(dim=1)\n",
    "\n",
    "for i in range(16):\n",
    "    print(tokenizer.decode(data['input_ids'][i], skip_special_tokens=True))\n",
    "    print('label=', data['labels'][i].item())\n",
    "    print('predict=', out[i].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
